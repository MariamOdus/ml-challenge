# 14 Days of ML: Machine Learning Algorithms Challenge

## Overview
This project works as a complete machine learning journey using different data, exploring and evaluating 13 different machine learning algorithms. The goal is to understand how a wide range of models — from simple approaches like linear regression to more advanced methods such as neural networks — can be applied to extract insights from data.

Along the way, we will compare the strengths, limitations, and practical suitability of each algorithm for different types of analytical questions, such as prediction, Classification, and identifying patterns.

The aim of this challenge is to work as a fun way to learn the theory about each of the popular machine learning odels, it starts with researching each one, learning the maths and theory behind them and then practising the implementation of a relevant dataset. By the end of this the aim is to have written 14 different files describing and evaluating each model and a final evaluation on the experience learnig about each model and their strengths and limitations in answering questions.

## Dataset
Each Machine Learning Model has its own dataset, each can be found in individual implementations or alternatively in the data folder of the project. Below are a compliation of the data sources used. 
- Sources: [Kaggle](https://www.kaggle.com/datasets)
- Sources: [UC Irvine](https://archive.ics.uci.edu/)

## Models Explored
- [x] Day 1: Linear Regression
- [x] Day 2: Logisitic Regression  
- [ ] Day 3: Decision Trees
- [ ] Day 4: Random Forest
- [ ] Day 5: Gradient Boosting
- [ ] Day 6: XGBoost
- [ ] Day 7: SVM
- [ ] Day 8: KNN
- [ ] Day 9: Naive Bayes
- [ ] Day 10: Hierachal Clustering
- [ ] Day 11: Neural Networks
- [ ] Day 12: CNN
- [ ] Day 13: RNN/LSTM


## Key Insights
*Will be updated as models are completed...*

## How to Navigate
Each day has:
- `/notebooks/XX_model_name.ipynb` - Code implementation
- `/reports/XX_model_name_report.md` - Detailed analysis
